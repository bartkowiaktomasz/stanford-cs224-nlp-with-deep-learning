{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6oqGiIXvrMl"
   },
   "source": [
    "# CS224N: JAX Tutorial (Spring '24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gk1UKaNvrMv"
   },
   "source": [
    "## Introduction\n",
    "Let's start by importing JAX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "u0ukr7quvrMx"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "\n",
    "# Import pprint, module we use for making our print statements prettier\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k10ZRdcBwDP3"
   },
   "source": [
    "We are all set to start our tutorial. Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLdSN9ZXvrM0"
   },
   "source": [
    "## Part 1: Tensors\n",
    "\n",
    "Each tensor is a multi-dimensional matrix; for example, a 256x256 square image might be represented by a `3x256x256` tensor, where the first dimension represents color. Here's how to create a tensor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXD7cTLTh4oF",
    "outputId": "e8662dba-7c52-4324-a4f7-fd10792fcb91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "list_of_lists = [\n",
    "  [1, 2, 3],\n",
    "  [4, 5, 6],\n",
    "]\n",
    "print(list_of_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G2u7NOqWNJ7c",
    "outputId": "7be0d98b-cd5c-499d-a870-0016c0476ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "data = jnp.array(list_of_lists)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-VLgHhj0n3LM",
    "outputId": "361eaa7b-d240-4c79-fafd-4d3ba9991d3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n"
     ]
    }
   ],
   "source": [
    "# Initializing a tensor\n",
    "data = jnp.array([\n",
    "    [0, 1],\n",
    "    [2, 3],\n",
    "    [4, 5]\n",
    "])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1i7vrR1_oO4I"
   },
   "source": [
    "Each tensor has a **data type**: the major data types you'll need to worry about are floats (`float32`) and integers (`int`). You can specify the data type explicitly when you create the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7nMdqgMoLOa",
    "outputId": "684c26eb-017b-4c9c-b66f-8851568a35f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [2. 3.]\n",
      " [4. 5.]]\n"
     ]
    }
   ],
   "source": [
    "# Initializing a tensor with an explicit data type\n",
    "# Notice the dots after the numbers, which specify that they're floats\n",
    "data = jnp.array([\n",
    "    [0, 1],\n",
    "    [2, 3],\n",
    "    [4, 5]\n",
    "], dtype=\"float32\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4vr6EYbiOEJ",
    "outputId": "344bda95-1691-47b7-f367-3d17481c2fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11111111 1.        ]\n",
      " [2.         3.        ]\n",
      " [4.         5.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Initializing a tensor with an explicit data type\n",
    "# Notice the dots after the numbers, which specify that they're floats\n",
    "data = jnp.array([\n",
    "    [0.11111111, 1],\n",
    "    [2, 3],\n",
    "    [4, 5]\n",
    "], dtype=\"float32\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnB8J23WiUTi",
    "outputId": "fae5e40f-2ca8-4ec5-a794-4dd66e516867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11111111 1.        ]\n",
      " [2.         3.        ]\n",
      " [4.         5.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Initializing a tensor with an implicit data type\n",
    "# Notice the dots after the numbers, which specify that they're floats\n",
    "data = jnp.array([\n",
    "    [0.11111111, 1],\n",
    "    [2, 3],\n",
    "    [4, 5]\n",
    "])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiGCmTsrpkP-"
   },
   "source": [
    "Utility functions also exist to create tensors with given shapes and contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tn-N-z_qYj0",
    "outputId": "df692e12-9f8b-458b-b70f-8f4ee667c101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "zeros = jnp.zeros((2, 5))  # a tensor of all zeros\n",
    "print(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ue26M5Npqoe3",
    "outputId": "98b18695-a174-4b61-8545-a32fa1127ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "ones = jnp.ones((3, 4))   # a tensor of all ones\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdvaujtvqokI",
    "outputId": "77123765-a189-4d8c-ac6b-e2e4a772717f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "rr = jnp.arange(1, 10) # range from [1, 10)\n",
    "print(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lK3q3LRHipHB",
    "outputId": "23d9bdfd-5b9b-45c9-8048-fc469859d614"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDQ-v6AFiyco",
    "outputId": "5ea664d0-7968-4ebe-b824-01d025b927e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 2,  4,  6,  8, 10, 12, 14, 16, 18], dtype=int32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OFcjwshvi3pC",
    "outputId": "81bb1488-0c44-40c4-b381-89d5ffbdf921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A is [[1. 2.]\n",
      " [2. 3.]\n",
      " [4. 5.]]\n",
      "B is [[1. 2. 3. 4.]\n",
      " [5. 6. 7. 8.]]\n",
      "The product is [[11. 14. 17. 20.]\n",
      " [17. 22. 27. 32.]\n",
      " [29. 38. 47. 56.]]\n",
      "The other product is [[11. 14. 17. 20.]\n",
      " [17. 22. 27. 32.]\n",
      " [29. 38. 47. 56.]]\n"
     ]
    }
   ],
   "source": [
    "a = jnp.array([[1, 2], [2, 3], [4, 5]], dtype=jnp.float32)      # (3, 2)\n",
    "b = jnp.array([[1, 2, 3, 4], [5, 6, 7, 8]], dtype=jnp.float32)  # (2, 4)\n",
    "\n",
    "print(\"A is\", a)\n",
    "print(\"B is\", b)\n",
    "print(\"The product is\", a.dot(b)) #(3, 4)\n",
    "print(\"The other product is\", a @ b) # +, -, *, @"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCS5z1lip9lq"
   },
   "source": [
    "The **shape** of a matrix (which can be accessed by `.shape`) is defined as the dimensions of the matrix. Here's some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fMptIpZkq0da",
    "outputId": "0466da76-e096-4814-8ae9-c3c000751db1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "matr_2d = jnp.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(matr_2d.shape)\n",
    "print(matr_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWjD7WjPqC6t",
    "outputId": "6bd07e79-fb89-462c-df24-2e5b7e52d004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  3  4]\n",
      "  [-2  5  6  9]]\n",
      "\n",
      " [[ 5  6  7  2]\n",
      "  [ 8  9 10  4]]\n",
      "\n",
      " [[-3  2  2  1]\n",
      "  [ 4  6  5  9]]]\n",
      "(3, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "matr_3d = jnp.array([[[1, 2, 3, 4], [-2, 5, 6, 9]], [[5, 6, 7, 2], [8, 9, 10, 4]], [[-3, 2, 2, 1], [4, 6, 5, 9]]])\n",
    "print(matr_3d)\n",
    "print(matr_3d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wKqP85rrF-P"
   },
   "source": [
    "**Reshaping** tensors can be used to make batch operations easier (more on that later), but be careful that the data is reshaped in the order you expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HmUcqHYUrMu1",
    "outputId": "ba15f448-9355-4fd4-f773-a8eb32c577cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape is currently (15,)\n",
      "The contents are currently [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\n",
      "After reshaping, the shape is currently (5, 3)\n",
      "The contents are currently [[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]\n",
      " [13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "rr = jnp.arange(1, 16)\n",
    "print(\"The shape is currently\", rr.shape)\n",
    "print(\"The contents are currently\", rr)\n",
    "print()\n",
    "rr = rr.reshape(5, 3)\n",
    "print(\"After reshaping, the shape is currently\", rr.shape)\n",
    "print(\"The contents are currently\", rr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaykBuhoou3M"
   },
   "source": [
    "Finally, you can also inter-convert tensors with **NumPy arrays**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppYiPnlko1Ci",
    "outputId": "328decae-69bb-4f8d-9248-c182868bec9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a <class 'jaxlib.xla_extension.ArrayImpl'> [[1 0 5]]\n",
      "This is a <class 'numpy.ndarray'> [[1 0 5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# numpy.ndarray --> torch.Tensor:\n",
    "arr = np.array([[1, 0, 5]])\n",
    "data = jnp.array(arr)\n",
    "print(f\"This is a {type(data)}\", data)\n",
    "\n",
    "# torch.Tensor --> numpy.ndarray:\n",
    "new_arr = np.array(data)\n",
    "print(f\"This is a {type(new_arr)}\", new_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyv1l431q9yA"
   },
   "source": [
    "One of the reasons why we use **tensors** is *vectorized operations*: operations that be conducted in parallel over a particular dimension of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kas2MEFDsJWk",
    "outputId": "fcbd6032-cbe2-4d83-f605-a4244e69fe95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is: [[ 1.  2.  3.  4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11. 12. 13. 14.]\n",
      " [15. 16. 17. 18. 19. 20. 21.]\n",
      " [22. 23. 24. 25. 26. 27. 28.]\n",
      " [29. 30. 31. 32. 33. 34. 35.]]\n",
      "Taking the sum over rows:\n",
      "[ 28.  77. 126. 175. 224.]\n",
      "Taking thep sum over columns:\n",
      "[ 75.  80.  85.  90.  95. 100. 105.]\n",
      "Taking the stdev over rows:\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "data = jnp.arange(1, 36, dtype=jnp.float32).reshape(5, 7)\n",
    "print(\"Data is:\", data)\n",
    "\n",
    "# We can perform operations like *sum* over each row...\n",
    "print(\"Taking the sum over rows:\")\n",
    "print(data.sum(axis=1)) #(5,)\n",
    "\n",
    "# or over each column.\n",
    "print(\"Taking thep sum over columns:\")\n",
    "print(data.sum(axis=0)) #(7,)\n",
    "\n",
    "# Other operations are available:\n",
    "print(\"Taking the stdev over rows:\")\n",
    "print(data.std(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1ByKJL_WYWv",
    "outputId": "d96d9b26-9742-4d25-ce39-800014ef1751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 2. 3.]\n",
      "  [4. 5. 6.]]]\n",
      "[5. 7. 9.]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "data = jnp.arange(1, 7, dtype=jnp.float32).reshape(1, 2, 3)\n",
    "print(data)\n",
    "print(data.sum(axis=0).sum(axis=0))\n",
    "print(data.sum(axis=0).sum(axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPRy-xtuk2tK",
    "outputId": "90348fd4-9f07-4274-83d7-168d06288292"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(21., dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJ8MjWEMxOVk"
   },
   "source": [
    "### Quiz\n",
    "\n",
    "Write code that creates a `jno.array` with the following contents:\n",
    "$\\begin{bmatrix} 1 & 2.2 & 9.6 \\\\ 4 & -7.2 & 6.3 \\end{bmatrix}$\n",
    "\n",
    "Now compute the average of each row (`.mean()`) and each column.\n",
    "\n",
    "What's the shape of the results?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "BK0YInGkn3Xy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.266667  1.0333335]\n",
      "[ 2.5       -2.5        7.9500003]\n"
     ]
    }
   ],
   "source": [
    "m = jnp.array([[1, 2.2, 9.6], [4, -7.2, 6.3]])\n",
    "# mean of each row\n",
    "print(m.mean(axis=1))\n",
    "# mean of each column\n",
    "print(m.mean(axis=0))\n",
    "\n",
    "# The shapes are (2) and (3) respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7BMktFFAkRA"
   },
   "source": [
    "**Indexing**\n",
    "\n",
    "You can access arbitrary elements of a tensor using the `[]` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRJN7ovWDsKV",
    "outputId": "9a207766-1b7e-4489-ef5f-e5d5dbe20d15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 1,  2],\n",
       "        [ 3,  4]],\n",
       "\n",
       "       [[ 5,  6],\n",
       "        [ 7,  8]],\n",
       "\n",
       "       [[ 9, 10],\n",
       "        [11, 12]]], dtype=int32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an example tensor\n",
    "x = jnp.array([\n",
    "    [[1, 2], [3, 4]],\n",
    "    [[5, 6], [7, 8]],\n",
    "    [[9, 10], [11, 12]]\n",
    "])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M67ZiOF1Heyc",
    "outputId": "83a18ebb-cc54-4608-c96c-543fa636babc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 2)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guXKE7m8AX1K",
    "outputId": "edffdcfd-d250-4749-b31c-0908b2674529"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1, 2],\n",
       "       [3, 4]], dtype=int32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the 0th element, which is the first row\n",
    "x[0] # Equivalent to x[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zn4pW2rkmXuj",
    "outputId": "514236c4-7fc5-46cb-f84f-ff3be2d4e6a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1,  2],\n",
       "       [ 5,  6],\n",
       "       [ 9, 10]], dtype=int32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8m8EyVvES4-"
   },
   "source": [
    "We can also index into multiple dimensions with `:`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Z6GFUcuEL85",
    "outputId": "13011b02-d061-43b7-ef2b-cf188323c80c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1, 5, 9], dtype=int32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top left element of each element in our tensor\n",
    "x[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRkMhiJNnWAt",
    "outputId": "3b93bd7f-373a-47c2-a67d-71315e5e4f8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 1,  2],\n",
       "        [ 3,  4]],\n",
       "\n",
       "       [[ 5,  6],\n",
       "        [ 7,  8]],\n",
       "\n",
       "       [[ 9, 10],\n",
       "        [11, 12]]], dtype=int32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rm8vc3nuXaEw"
   },
   "source": [
    "We can also access arbitrary elements in each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4xl6CW3RrEw",
    "outputId": "18672bf8-3d9c-4fb4-c967-7d26608cde2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[1, 2],\n",
       "        [3, 4]],\n",
       "\n",
       "       [[1, 2],\n",
       "        [3, 4]],\n",
       "\n",
       "       [[5, 6],\n",
       "        [7, 8]],\n",
       "\n",
       "       [[5, 6],\n",
       "        [7, 8]]], dtype=int32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's access the 0th and 1st elements, each twice\n",
    "# same as stacking x[0], x[0], x[1], x[1]\n",
    "i = jnp.array([0, 0, 1, 1])\n",
    "x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3QYZ8k7Wvqp",
    "outputId": "2fb10213-5441-4326-ddf3-6e5014922304"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 5,  6],\n",
       "       [ 9, 10]], dtype=int32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's access the 0th elements of the 1st and 2nd elements\n",
    "\n",
    "i = jnp.array([1, 2])\n",
    "j = jnp.array([0])\n",
    "x[i, j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAELXC--IHS7"
   },
   "source": [
    "We can get a `Python` scalar value from a tensor with `item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BM-ZujN2IGaQ",
    "outputId": "ece51f0a-f1d2-435c-d75f-0496035a7d40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1, dtype=int32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NwxK7d_Ycgs",
    "outputId": "b960776c-df09-49ad-def1-e951c55c1d10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, 0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGod5kHa6OOF"
   },
   "source": [
    "### Exercise:\n",
    "\n",
    "Write code that creates a `jnp.array` with the following contents:\n",
    "$\\begin{bmatrix} 1 & 2.2 & 9.6 \\\\ 4 & -7.2 & 6.3 \\end{bmatrix}$\n",
    "\n",
    "How do you get the first column? The first row?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 4.]\n",
      "[1.  2.2 9.6]\n"
     ]
    }
   ],
   "source": [
    "m2 = jnp.array([[1, 2.2, 9.6], [4, -7.2, 6.3]])\n",
    "# get the first column\n",
    "print(m2[:, 0])\n",
    "\n",
    "# get the first row\n",
    "print(m2[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Re8xiL37eAja"
   },
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(12., dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an example tensor\n",
    "x = jnp.array(2.)\n",
    "\n",
    "# Calculating the gradient of y with respect to x\n",
    "y = lambda x: x * x * 3 # 3x^2\n",
    "y_grad = jax.grad(y)\n",
    "y_grad(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYLWqKIoaOyd"
   },
   "source": [
    "## Neural Network Module\n",
    "\n",
    "So far we have looked into the tensors, their properties and basic operations on tensors. These are especially useful to get familiar with if we are building the layers of our network from scratch. We will utilize these in Assignment 2, but moving forward, we will use predefined blocks in the `nnx` module of `flax`. We will then put together these blocks to create complex networks. Let's start by importing this module with an alias so that we don't have to type `flax` every time we use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "qUmrDpbhV4Tn"
   },
   "outputs": [],
   "source": [
    "from flax import nnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joGvRWjEbak0"
   },
   "source": [
    "### **Linear Layer**\n",
    "We can use `nn.Linear(H_in, H_out)` to create a a linear layer. This will take a matrix of `(N, *, H_in)` dimensions and output a matrix of `(N, *, H_out)`. The `*` denotes that there could be arbitrary number of dimensions in between. The linear layer performs the operation `Ax+b`, where `A` and `b` are initialized randomly. If we don't want the linear layer to learn the bias parameters, we can initialize our layer with `bias=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XfnKI4-a5j9",
    "outputId": "ebce3d47-b720-4ff4-a279-83c2ab3513cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[-0.17026094, -0.6833216 ],\n",
       "        [-0.17026094, -0.6833216 ],\n",
       "        [-0.17026094, -0.6833216 ]],\n",
       "\n",
       "       [[-0.17026094, -0.6833216 ],\n",
       "        [-0.17026094, -0.6833216 ],\n",
       "        [-0.17026094, -0.6833216 ]]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the inputs\n",
    "input = jnp.ones((2, 3, 4))\n",
    "# N*H_in -> N*H_out\n",
    "\n",
    "# Make a linear layers transforming N,*,H_in dimensinal inputs to N,*,H_out\n",
    "# dimensional outputs\n",
    "linear = nnx.Linear(4, 2, rngs=nnx.Rngs(0))\n",
    "linear_output = linear(input)\n",
    "linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (2,))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.kernel.value.shape, linear.bias.value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_9XKtAFYpdI",
    "outputId": "992db13a-f581-4cfd-f840-fa49778e696e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[-0.31055146, -0.30089378],\n",
       "        [ 0.44153705, -0.25188616],\n",
       "        [-0.03567746, -0.9629547 ],\n",
       "        [-0.26556906,  0.8324131 ]], dtype=float32),\n",
       " Array([0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.kernel.value, linear.bias.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAXCCu9keUlW"
   },
   "source": [
    "### **Other Module Layers**\n",
    "There are several other preconfigured layers in the `nnx` module. Some commonly used examples are `nnx.Conv`, `nnx.ConvTranspose`, `nn.BatchNorm`, among many others. We will learn more about these as we progress in the course. For now, the only important thing to remember is that we can treat each of these layers as plug and play components: we will be providing the required dimensions and `jax` will take care of setting them up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yslDOK66fYWn"
   },
   "source": [
    "### **Activation Function Layer**\n",
    "We can also use the `nnx` module to apply activations functions to our tensors. Activation functions are used to add non-linearity to our network. Some examples of activations functions are `nnx.relu`, `nnx.sigmoid` and `nnx.leaky_relu`. Activation functions operate on each element seperately, so the shape of the tensors we get as an output are the same as the ones we pass in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9v5FjQtd4Ck",
    "outputId": "2cc3cdf3-8153-4a43-d642-420440956523"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[0.45753732, 0.3355204 ],\n",
       "        [0.45753732, 0.3355204 ],\n",
       "        [0.45753732, 0.3355204 ]],\n",
       "\n",
       "       [[0.45753732, 0.3355204 ],\n",
       "        [0.45753732, 0.3355204 ],\n",
       "        [0.45753732, 0.3355204 ]]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = nnx.sigmoid(linear_output)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiYTthJwhEYT"
   },
   "source": [
    "### **Putting the Layers Together**\n",
    "So far we have seen that we can create layers and pass the output of one as the input of the next. Instead of creating intermediate tensors and passing them around, we can use `nn.Sequentual`, which does exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xtJeOqLxhBLY",
    "outputId": "054d47ee-ae85-4cc7-8cd7-07e446232f84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[0.45753732, 0.3355204 ],\n",
       "        [0.45753732, 0.3355204 ],\n",
       "        [0.45753732, 0.3355204 ]],\n",
       "\n",
       "       [[0.45753732, 0.3355204 ],\n",
       "        [0.45753732, 0.3355204 ],\n",
       "        [0.45753732, 0.3355204 ]]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = nnx.Sequential(\n",
    "    nnx.Linear(4, 2, rngs=nnx.Rngs(0))\n",
    ")\n",
    "\n",
    "input = jnp.ones((2,3,4))\n",
    "output = nnx.sigmoid(block(input))\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkJ81p3GUVPM"
   },
   "source": [
    "### Custom Modules\n",
    "\n",
    "Instead of using the predefined modules, we can also build our own by extending the `nnx.Module` class. For example, we can build a the `nnx.Linear` (which also extends `nnx.Module`) on our own using the tensor introduced earlier! We can also build new, more complex modules, such as a custom neural network. You will be practicing these in the later assignment.\n",
    "\n",
    "To create a custom module, the first thing we have to do is to extend the `nnx.Module`. We can then initialize our parameters in the `__init__` function, starting with a call to the `__init__` function of the super class. All the class attributes we define which are `nn` module objects are treated as parameters, which can be learned during the training.\n",
    "\n",
    "All classes extending `nnx.Module` are also expected to implement a `__call__(x)` function, where `x` is a tensor. This is the function that is called when a parameter is passed to our module, such as in `model(x)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nnx.Module):\n",
    "\n",
    "  def __init__(self, input_size: int, hidden_size: int, output_size: int, rngs: nnx.Rngs = nnx.Rngs(0)):\n",
    "    # Call to the __init__ function of the super class\n",
    "    super(MultiLayerPerceptron, self).__init__()\n",
    "\n",
    "    # Bookkeeping: Saving the initialization parameters\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "\n",
    "    self.linear = nnx.Linear(self.input_size, self.hidden_size, rngs=rngs)\n",
    "    self.linear2 = nnx.Linear(self.hidden_size, self.output_size, rngs=rngs)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    output = nnx.softmax(self.linear2(nnx.relu(self.linear(x))))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQelcFo5bXgU"
   },
   "source": [
    "Now that we have defined our class, we can instantiate it and see what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.2449855 , 0.30524373, 0.44977078],\n",
       "       [0.3758987 , 0.20768349, 0.41641778]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = jax.random.key(seed=100)\n",
    "input = jax.random.normal(shape=(2, 5), key=key)\n",
    "\n",
    "model = MultiLayerPerceptron(5, 64, 3, rngs=nnx.Rngs(0))\n",
    "model(input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCCbjc-Fb2-B"
   },
   "source": [
    "We can inspect the parameters of our model with `nnx.display(model)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d23soYIb2WZ",
    "outputId": "b520a8fc-3911-495c-cd48-49f1ade47beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  input_size=5,\n",
      "  hidden_size=64,\n",
      "  output_size=3,\n",
      "  linear=Linear(\n",
      "    kernel=Param(\n",
      "      value=Array(shape=(5, 64), dtype=float32)\n",
      "    ),\n",
      "    bias=Param(\n",
      "      value=Array(shape=(64,), dtype=float32)\n",
      "    ),\n",
      "    in_features=5,\n",
      "    out_features=64,\n",
      "    use_bias=True,\n",
      "    dtype=None,\n",
      "    param_dtype=<class 'jax.numpy.float32'>,\n",
      "    precision=None,\n",
      "    kernel_init=<function variance_scaling.<locals>.init at 0x11eca6ca0>,\n",
      "    bias_init=<function zeros at 0x111902ac0>,\n",
      "    dot_general=<function dot_general at 0x111196340>\n",
      "  ),\n",
      "  linear2=Linear(\n",
      "    kernel=Param(\n",
      "      value=Array(shape=(64, 3), dtype=float32)\n",
      "    ),\n",
      "    bias=Param(\n",
      "      value=Array(shape=(3,), dtype=float32)\n",
      "    ),\n",
      "    in_features=64,\n",
      "    out_features=3,\n",
      "    use_bias=True,\n",
      "    dtype=None,\n",
      "    param_dtype=<class 'jax.numpy.float32'>,\n",
      "    precision=None,\n",
      "    kernel_init=<function variance_scaling.<locals>.init at 0x11eca6ca0>,\n",
      "    bias_init=<function zeros at 0x111902ac0>,\n",
      "    dot_general=<function dot_general at 0x111196340>\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "nnx.display(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5JegycOdMFy"
   },
   "source": [
    "## Optimization\n",
    "Having the gradients isn't enought for our models to learn. We also need to know how to update the parameters of our models. This is where the optimizers comes in. `optax` module contains several optimizers that we can use. Some popular examples are `optax.sgd` and `optax.adam`. Optimizers has a learning rate (`learning_rate`) parameter, which determines how big of an update will be made in every step. Different optimizers have different hyperparameters as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "W0F-TvV0kk-I"
   },
   "outputs": [],
   "source": [
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgak6o5dlQWF"
   },
   "source": [
    "After we have our optimization function, we can define a `loss` that we want to optimize for. We can either define the loss ourselves, or use one of the predefined loss function in such as `optax.losses.squared_error`. Let's put everything together now! We will start by creating some dummy data.\n",
    "\n",
    "Note: In JAX, `loss` function, when used with `nnx.value_and_grad(loss)(model, y)` needs to accept `model` as first argument, since `value_and_grad` calculates gradient w.r.t. first positional argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ohe = jax.nn.one_hot(jnp.ones((10, 5)), 5)\n",
    "y_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGYFiaT_vXBn",
    "outputId": "4f4a1f82-f708-4f8b-c5c2-5232cbbe8615"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[-1.2262332 ,  1.4810336 , -0.5197212 ,  1.5202414 ,\n",
       "          0.45887414],\n",
       "        [ 0.10311025,  1.4125631 , -0.39090064, -0.09483104,\n",
       "         -0.74713457],\n",
       "        [ 0.25137082,  1.4861655 , -0.76141524, -0.13572052,\n",
       "          0.91742074],\n",
       "        [ 0.08653314,  1.8053247 ,  1.2471547 ,  0.9763958 ,\n",
       "          1.220573  ],\n",
       "        [ 1.8219421 ,  0.20261335, -0.15477557,  0.21770734,\n",
       "          0.6405267 ]],\n",
       "\n",
       "       [[ 1.1118156 ,  1.0775955 ,  0.6424729 , -1.0053515 ,\n",
       "          0.99456733],\n",
       "        [-0.3395303 ,  1.3200217 ,  0.10800842, -0.28815672,\n",
       "         -1.5289674 ],\n",
       "        [ 1.3016586 ,  2.3308759 ,  0.14011298, -1.5961647 ,\n",
       "         -0.45299408],\n",
       "        [-1.8585554 , -0.55924857,  0.52025634,  0.864114  ,\n",
       "         -0.93108404],\n",
       "        [-0.44154626,  1.0209888 , -0.153729  ,  1.3608798 ,\n",
       "         -0.42661062]],\n",
       "\n",
       "       [[-0.78405386,  0.55537456, -1.4077625 ,  0.5685388 ,\n",
       "         -0.79089546],\n",
       "        [-1.0732454 ,  1.2097561 , -0.99139154,  0.74864846,\n",
       "          0.34770265],\n",
       "        [ 1.0340692 ,  0.709311  , -1.4985577 , -0.48999268,\n",
       "         -1.1070158 ],\n",
       "        [-0.21927312,  1.5653802 , -0.46300587, -1.1787301 ,\n",
       "         -0.1547051 ],\n",
       "        [ 0.23527744,  1.3942975 ,  1.9939955 , -0.2198477 ,\n",
       "         -0.57585317]],\n",
       "\n",
       "       [[ 0.7253321 , -0.272277  ,  0.49607602, -1.6861411 ,\n",
       "          1.6457357 ],\n",
       "        [ 0.9373855 ,  1.4217912 , -0.85199624, -1.4486812 ,\n",
       "          1.2892627 ],\n",
       "        [ 0.07651351,  2.6528602 , -0.23457973, -1.1593182 ,\n",
       "         -1.979584  ],\n",
       "        [ 1.2832142 ,  0.08126646,  3.4051304 ,  0.07455219,\n",
       "          1.704082  ],\n",
       "        [ 0.41238344,  1.2850481 , -1.3502823 , -0.28335637,\n",
       "         -0.45237467]],\n",
       "\n",
       "       [[ 1.2473636 ,  1.3313768 ,  0.5005933 ,  0.723471  ,\n",
       "          1.2568095 ],\n",
       "        [ 0.0366999 ,  1.4904972 ,  0.6681471 ,  0.7648959 ,\n",
       "         -0.47335374],\n",
       "        [ 0.08767174,  0.03445423, -0.1843063 ,  0.29939076,\n",
       "         -0.10147843],\n",
       "        [ 0.2096157 ,  2.351279  , -1.8423656 , -0.9274681 ,\n",
       "          0.8577185 ],\n",
       "        [ 1.6655337 ,  1.3773808 ,  0.75960714,  1.3823305 ,\n",
       "         -1.4887098 ]],\n",
       "\n",
       "       [[ 0.94070727,  0.7390801 , -0.40999392, -0.19116831,\n",
       "          0.21923657],\n",
       "        [ 2.2021654 ,  1.7058115 ,  1.1657809 ,  0.32866785,\n",
       "          1.8230413 ],\n",
       "        [ 0.9278685 ,  1.4685113 , -0.04959368,  2.0730934 ,\n",
       "         -0.37946075],\n",
       "        [ 0.01109016,  0.02359724, -0.26191714,  0.41205716,\n",
       "         -1.4169941 ],\n",
       "        [-0.30491692,  2.1468592 , -2.2399108 ,  2.1306708 ,\n",
       "          0.52241564]],\n",
       "\n",
       "       [[ 1.1533985 ,  0.48322517,  0.72450125, -1.3116418 ,\n",
       "         -1.0239191 ],\n",
       "        [-0.40091616,  2.5830765 , -0.06932633,  0.2305277 ,\n",
       "         -1.3427969 ],\n",
       "        [-0.01102726,  1.8562906 ,  0.45592773,  0.2910215 ,\n",
       "          0.77518356],\n",
       "        [ 0.93075293,  1.2457987 ,  0.5706566 ,  1.2647516 ,\n",
       "          2.5782542 ],\n",
       "        [-1.3551418 ,  1.6247852 ,  0.5990466 , -0.04411131,\n",
       "         -0.0243894 ]],\n",
       "\n",
       "       [[-0.39371023,  1.1185062 , -1.1851367 ,  1.5424595 ,\n",
       "         -2.216289  ],\n",
       "        [ 0.39176375,  0.9702841 , -0.50305456,  0.04746856,\n",
       "         -0.12861116],\n",
       "        [ 0.49402782,  1.4023137 , -2.559133  ,  0.03105655,\n",
       "         -0.4089135 ],\n",
       "        [-0.82103735,  0.506342  ,  0.31861275,  0.12541163,\n",
       "         -0.91848475],\n",
       "        [ 1.605836  ,  1.8946204 , -0.3089735 , -0.8403102 ,\n",
       "          0.32562104]],\n",
       "\n",
       "       [[-0.6504496 ,  2.3693366 , -2.068631  , -1.0967265 ,\n",
       "         -1.8532306 ],\n",
       "        [-1.4318246 ,  0.04228675, -1.4230052 , -0.1857827 ,\n",
       "         -1.0941067 ],\n",
       "        [-1.072551  ,  0.84213996, -0.1666553 ,  0.37154135,\n",
       "          1.7436433 ],\n",
       "        [-0.08526584, -1.0109596 , -0.30418292,  1.0515742 ,\n",
       "         -2.1959562 ],\n",
       "        [-0.5521193 , -0.369776  ,  0.26237655,  0.83650964,\n",
       "          0.2545647 ]],\n",
       "\n",
       "       [[-0.36761758,  0.520208  ,  0.914202  , -0.48818752,\n",
       "         -0.47285813],\n",
       "        [-0.8259077 , -0.35989344, -0.7762738 , -2.1024384 ,\n",
       "         -1.1642861 ],\n",
       "        [-0.07110776,  1.2804136 , -1.0178518 ,  1.2105275 ,\n",
       "          0.5446918 ],\n",
       "        [ 0.76588476,  1.1973426 ,  0.52036107,  0.06082546,\n",
       "         -1.815073  ],\n",
       "        [-0.43616125, -0.22550595,  1.0385162 , -0.22825617,\n",
       "          0.97415006]]], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = jax.random.key(seed=100)\n",
    "\n",
    "# Create the y data\n",
    "# y = jnp.ones((10, 5))\n",
    "y = y_ohe\n",
    "\n",
    "# Add some noise to our goal y to generate our x\n",
    "# We want out model to predict our original data, albeit the noise\n",
    "x = y + jax.random.normal(key=key, shape=y.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEsiOdpWvfLj"
   },
   "source": [
    "Now, we can define our model, optimizer and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18577083945274353"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = MultiLayerPerceptron(5, 64, 5)\n",
    "\n",
    "# Define the optimizer\n",
    "adam = optax.adam(learning_rate=1e-1)\n",
    "\n",
    "# Calculate how our model is doing now\n",
    "y_pred = model(x)\n",
    "loss = optax.losses.squared_error(y_pred, y).mean().item()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLayerPerceptron(\n",
       "  input_size=5,\n",
       "  hidden_size=64,\n",
       "  output_size=5,\n",
       "  linear=Linear(\n",
       "    kernel=Param(\n",
       "      value=Array(shape=(5, 64), dtype=float32)\n",
       "    ),\n",
       "    bias=Param(\n",
       "      value=Array(shape=(64,), dtype=float32)\n",
       "    ),\n",
       "    in_features=5,\n",
       "    out_features=64,\n",
       "    use_bias=True,\n",
       "    dtype=None,\n",
       "    param_dtype=<class 'jax.numpy.float32'>,\n",
       "    precision=None,\n",
       "    kernel_init=<function variance_scaling.<locals>.init at 0x11eca6ca0>,\n",
       "    bias_init=<function zeros at 0x111902ac0>,\n",
       "    dot_general=<function dot_general at 0x111196340>\n",
       "  ),\n",
       "  linear2=Linear(\n",
       "    kernel=Param(\n",
       "      value=Array(shape=(64, 5), dtype=float32)\n",
       "    ),\n",
       "    bias=Param(\n",
       "      value=Array(shape=(5,), dtype=float32)\n",
       "    ),\n",
       "    in_features=64,\n",
       "    out_features=5,\n",
       "    use_bias=True,\n",
       "    dtype=None,\n",
       "    param_dtype=<class 'jax.numpy.float32'>,\n",
       "    precision=None,\n",
       "    kernel_init=<function variance_scaling.<locals>.init at 0x11eca6ca0>,\n",
       "    bias_init=<function zeros at 0x111902ac0>,\n",
       "    dot_general=<function dot_general at 0x111196340>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: traing loss: 0.18577083945274353\n",
      "Epoch 1: traing loss: 0.1820353865623474\n",
      "Epoch 2: traing loss: 0.17819486558437347\n",
      "Epoch 3: traing loss: 0.17424796521663666\n",
      "Epoch 4: traing loss: 0.1701943427324295\n",
      "Epoch 5: traing loss: 0.16603554785251617\n",
      "Epoch 6: traing loss: 0.1617729216814041\n",
      "Epoch 7: traing loss: 0.15740953385829926\n",
      "Epoch 8: traing loss: 0.1529502123594284\n",
      "Epoch 9: traing loss: 0.14840103685855865\n",
      "Epoch 10: traing loss: 0.14376921951770782\n",
      "Epoch 11: traing loss: 0.1390639990568161\n",
      "Epoch 12: traing loss: 0.13429582118988037\n",
      "Epoch 13: traing loss: 0.1294756978750229\n",
      "Epoch 14: traing loss: 0.12461644411087036\n",
      "Epoch 15: traing loss: 0.1197335496544838\n",
      "Epoch 16: traing loss: 0.11484318971633911\n",
      "Epoch 17: traing loss: 0.10996294766664505\n",
      "Epoch 18: traing loss: 0.10511116683483124\n",
      "Epoch 19: traing loss: 0.10030772536993027\n",
      "Epoch 20: traing loss: 0.09557072818279266\n",
      "Epoch 21: traing loss: 0.09092001616954803\n",
      "Epoch 22: traing loss: 0.08637544512748718\n",
      "Epoch 23: traing loss: 0.08195499330759048\n",
      "Epoch 24: traing loss: 0.0776737779378891\n",
      "Epoch 25: traing loss: 0.07354703545570374\n",
      "Epoch 26: traing loss: 0.06958480924367905\n",
      "Epoch 27: traing loss: 0.06579512357711792\n",
      "Epoch 28: traing loss: 0.06218500807881355\n",
      "Epoch 29: traing loss: 0.058759503066539764\n",
      "Epoch 30: traing loss: 0.05551986023783684\n",
      "Epoch 31: traing loss: 0.052464473992586136\n",
      "Epoch 32: traing loss: 0.0495905801653862\n",
      "Epoch 33: traing loss: 0.04689345508813858\n",
      "Epoch 34: traing loss: 0.044366784393787384\n",
      "Epoch 35: traing loss: 0.04200412705540657\n",
      "Epoch 36: traing loss: 0.03979708254337311\n",
      "Epoch 37: traing loss: 0.03773743659257889\n",
      "Epoch 38: traing loss: 0.03581700474023819\n",
      "Epoch 39: traing loss: 0.0340273380279541\n",
      "Epoch 40: traing loss: 0.032359734177589417\n",
      "Epoch 41: traing loss: 0.03080599009990692\n",
      "Epoch 42: traing loss: 0.0293581560254097\n",
      "Epoch 43: traing loss: 0.02800896391272545\n",
      "Epoch 44: traing loss: 0.02675105445086956\n",
      "Epoch 45: traing loss: 0.025577500462532043\n",
      "Epoch 46: traing loss: 0.0244819987565279\n",
      "Epoch 47: traing loss: 0.023458419367671013\n",
      "Epoch 48: traing loss: 0.022501729428768158\n",
      "Epoch 49: traing loss: 0.02160698175430298\n",
      "Epoch 50: traing loss: 0.020769722759723663\n",
      "Epoch 51: traing loss: 0.019985709339380264\n",
      "Epoch 52: traing loss: 0.01925087347626686\n",
      "Epoch 53: traing loss: 0.018561474978923798\n",
      "Epoch 54: traing loss: 0.017913619056344032\n",
      "Epoch 55: traing loss: 0.017304427921772003\n",
      "Epoch 56: traing loss: 0.016731197014451027\n",
      "Epoch 57: traing loss: 0.01619124226272106\n",
      "Epoch 58: traing loss: 0.01568179950118065\n",
      "Epoch 59: traing loss: 0.015200743451714516\n",
      "Epoch 60: traing loss: 0.014746124856173992\n",
      "Epoch 61: traing loss: 0.014316107146441936\n",
      "Epoch 62: traing loss: 0.01390902604907751\n",
      "Epoch 63: traing loss: 0.013523290865123272\n",
      "Epoch 64: traing loss: 0.01315739843994379\n",
      "Epoch 65: traing loss: 0.012809914536774158\n",
      "Epoch 66: traing loss: 0.012479593977332115\n",
      "Epoch 67: traing loss: 0.01216533500701189\n",
      "Epoch 68: traing loss: 0.011866052635014057\n",
      "Epoch 69: traing loss: 0.011580144055187702\n",
      "Epoch 70: traing loss: 0.011307232081890106\n",
      "Epoch 71: traing loss: 0.011046478524804115\n",
      "Epoch 72: traing loss: 0.010796995833516121\n",
      "Epoch 73: traing loss: 0.010558201000094414\n",
      "Epoch 74: traing loss: 0.010329355485737324\n",
      "Epoch 75: traing loss: 0.010109924711287022\n",
      "Epoch 76: traing loss: 0.00989936850965023\n",
      "Epoch 77: traing loss: 0.009697138331830502\n",
      "Epoch 78: traing loss: 0.00950270052999258\n",
      "Epoch 79: traing loss: 0.009315689094364643\n",
      "Epoch 80: traing loss: 0.009135657921433449\n",
      "Epoch 81: traing loss: 0.00896217580884695\n",
      "Epoch 82: traing loss: 0.008794785477221012\n",
      "Epoch 83: traing loss: 0.008633272722363472\n",
      "Epoch 84: traing loss: 0.00847723800688982\n",
      "Epoch 85: traing loss: 0.008326462469995022\n",
      "Epoch 86: traing loss: 0.008180664852261543\n",
      "Epoch 87: traing loss: 0.008039560168981552\n",
      "Epoch 88: traing loss: 0.007902883924543858\n",
      "Epoch 89: traing loss: 0.007770405616611242\n",
      "Epoch 90: traing loss: 0.007641990203410387\n",
      "Epoch 91: traing loss: 0.007517446763813496\n",
      "Epoch 92: traing loss: 0.007396591827273369\n",
      "Epoch 93: traing loss: 0.007279138546437025\n",
      "Epoch 94: traing loss: 0.007164970505982637\n",
      "Epoch 95: traing loss: 0.007053984794765711\n",
      "Epoch 96: traing loss: 0.00694590387865901\n",
      "Epoch 97: traing loss: 0.006840705405920744\n",
      "Epoch 98: traing loss: 0.006738155614584684\n",
      "Epoch 99: traing loss: 0.006638220511376858\n"
     ]
    }
   ],
   "source": [
    "optimizer = nnx.Optimizer(model, optax.adam(1e-3))\n",
    "\n",
    "def loss(model, y):\n",
    "    y_pred = model(x)\n",
    "    loss_ = optax.losses.squared_error(y_pred, y).mean()\n",
    "    return loss_\n",
    "\n",
    "# Set the number of epoch, which determines the number of training iterations\n",
    "n_epoch = 100\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "\n",
    "  loss_, grads = nnx.value_and_grad(loss)(model, y)\n",
    "  optimizer.update(grads)  # In place updates.\n",
    "\n",
    "  # # Print stats\n",
    "  print(f\"Epoch {epoch}: traing loss: {loss_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nXApd82wlsF"
   },
   "source": [
    "You can see that our loss is decreasing. Let's check the predictions of our model now and see if they are close to our original `y`, which was all `1s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRqE7P9EtvuS",
    "outputId": "2b2db865-2bb2-4598-85ee-625b9fab7ef9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[2.67716479e-02, 9.47577178e-01, 1.36385802e-02, 5.20828832e-03,\n",
       "         6.80439686e-03],\n",
       "        [6.35656118e-02, 8.13051045e-01, 6.00242838e-02, 2.36921944e-02,\n",
       "         3.96668203e-02],\n",
       "        [4.55217399e-02, 8.83715987e-01, 3.61319482e-02, 1.23430826e-02,\n",
       "         2.22871881e-02],\n",
       "        [8.32984317e-03, 9.69358802e-01, 8.59795883e-03, 3.20940767e-03,\n",
       "         1.05040418e-02],\n",
       "        [2.86420155e-02, 9.07064795e-01, 2.70510837e-02, 1.87784657e-02,\n",
       "         1.84635464e-02]],\n",
       "\n",
       "       [[1.99175198e-02, 9.14099336e-01, 3.17909084e-02, 1.43124331e-02,\n",
       "         1.98798031e-02],\n",
       "        [3.56519148e-02, 8.78746033e-01, 3.81462388e-02, 1.44328000e-02,\n",
       "         3.30230631e-02],\n",
       "        [6.28624018e-03, 9.83483851e-01, 6.50156848e-03, 1.14651758e-03,\n",
       "         2.58181687e-03],\n",
       "        [8.98824483e-02, 8.34748805e-01, 2.82318518e-02, 1.36638843e-02,\n",
       "         3.34729291e-02],\n",
       "        [6.88102767e-02, 8.36020827e-01, 4.01259586e-02, 2.32554059e-02,\n",
       "         3.17875594e-02]],\n",
       "\n",
       "       [[5.25862239e-02, 9.05382335e-01, 1.84453428e-02, 8.12069140e-03,\n",
       "         1.54654579e-02],\n",
       "        [5.32492027e-02, 8.98649096e-01, 2.32438985e-02, 9.18392558e-03,\n",
       "         1.56738833e-02],\n",
       "        [2.65626144e-02, 9.44518745e-01, 2.00654231e-02, 3.91064491e-03,\n",
       "         4.94253496e-03],\n",
       "        [5.32277972e-02, 8.73167455e-01, 3.78509387e-02, 1.05623491e-02,\n",
       "         2.51913648e-02],\n",
       "        [8.96662194e-03, 9.46429431e-01, 1.60332974e-02, 3.79294856e-03,\n",
       "         2.47776639e-02]],\n",
       "\n",
       "       [[1.27356667e-02, 9.23502147e-01, 2.10516602e-02, 1.77201685e-02,\n",
       "         2.49902587e-02],\n",
       "        [1.31227113e-02, 9.66193616e-01, 1.23762153e-02, 3.10866465e-03,\n",
       "         5.19876741e-03],\n",
       "        [5.91512863e-03, 9.84958291e-01, 5.43645862e-03, 8.91880074e-04,\n",
       "         2.79823551e-03],\n",
       "        [1.56059326e-03, 9.81767714e-01, 1.05568841e-02, 1.51859084e-03,\n",
       "         4.59633861e-03],\n",
       "        [4.82936092e-02, 8.92375946e-01, 3.82668562e-02, 9.24477540e-03,\n",
       "         1.18188020e-02]],\n",
       "\n",
       "       [[1.52696939e-02, 9.43282783e-01, 1.34720467e-02, 1.08160591e-02,\n",
       "         1.71594545e-02],\n",
       "        [4.15631160e-02, 8.55405569e-01, 4.03166749e-02, 1.62812397e-02,\n",
       "         4.64334935e-02],\n",
       "        [1.67947665e-01, 4.39271957e-01, 1.45980701e-01, 1.11846268e-01,\n",
       "         1.34953380e-01],\n",
       "        [1.24434792e-02, 9.75007534e-01, 9.50831920e-03, 8.84171575e-04,\n",
       "         2.15654401e-03],\n",
       "        [1.51915420e-02, 9.58553135e-01, 1.46749904e-02, 2.00687512e-03,\n",
       "         9.57348105e-03]],\n",
       "\n",
       "       [[7.41118863e-02, 7.80120552e-01, 6.50982857e-02, 4.23027836e-02,\n",
       "         3.83665711e-02],\n",
       "        [2.20397371e-03, 9.90193903e-01, 2.62983260e-03, 1.75840396e-03,\n",
       "         3.21386429e-03],\n",
       "        [1.89674217e-02, 9.60567713e-01, 9.23762750e-03, 4.55485517e-03,\n",
       "         6.67244103e-03],\n",
       "        [7.68252760e-02, 7.58020639e-01, 6.36897236e-02, 2.66162083e-02,\n",
       "         7.48481825e-02],\n",
       "        [3.26421624e-03, 9.94884908e-01, 1.07004424e-03, 3.26395006e-04,\n",
       "         4.54479799e-04]],\n",
       "\n",
       "       [[1.82008334e-02, 9.34184909e-01, 2.29347404e-02, 1.00070685e-02,\n",
       "         1.46724517e-02],\n",
       "        [1.21639883e-02, 9.65065598e-01, 1.17517365e-02, 1.89882517e-03,\n",
       "         9.11988039e-03],\n",
       "        [2.59712432e-02, 9.12736416e-01, 2.68538203e-02, 8.51619430e-03,\n",
       "         2.59223040e-02],\n",
       "        [4.24288958e-03, 9.84729588e-01, 4.02315240e-03, 3.27888224e-03,\n",
       "         3.72545188e-03],\n",
       "        [3.93245555e-02, 8.90442133e-01, 3.68779562e-02, 5.85393608e-03,\n",
       "         2.75013708e-02]],\n",
       "\n",
       "       [[1.33293867e-02, 9.73172545e-01, 5.70846722e-03, 1.71204051e-03,\n",
       "         6.07753871e-03],\n",
       "        [1.05640680e-01, 7.01417625e-01, 8.92535821e-02, 4.73410748e-02,\n",
       "         5.63470237e-02],\n",
       "        [9.94127896e-03, 9.82904911e-01, 5.63859660e-03, 5.67236217e-04,\n",
       "         9.47921129e-04],\n",
       "        [8.92505199e-02, 6.99465692e-01, 7.35557601e-02, 4.24930677e-02,\n",
       "         9.52350274e-02],\n",
       "        [1.28623899e-02, 9.67332065e-01, 1.15304375e-02, 3.74765531e-03,\n",
       "         4.52750735e-03]],\n",
       "\n",
       "       [[5.04818046e-03, 9.90775287e-01, 3.10325855e-03, 3.30593699e-04,\n",
       "         7.42643606e-04],\n",
       "        [4.55189645e-02, 9.30024683e-01, 8.21488630e-03, 4.87436773e-03,\n",
       "         1.13670817e-02],\n",
       "        [4.54036593e-02, 8.93445671e-01, 2.74934378e-02, 9.15796589e-03,\n",
       "         2.44991593e-02],\n",
       "        [3.08395326e-02, 9.21001792e-01, 1.76958106e-02, 3.81545373e-03,\n",
       "         2.66472865e-02],\n",
       "        [1.51382059e-01, 5.81576228e-01, 1.09407611e-01, 7.59996921e-02,\n",
       "         8.16343799e-02]],\n",
       "\n",
       "       [[6.77596629e-02, 7.08044648e-01, 8.45350921e-02, 3.81252617e-02,\n",
       "         1.01535313e-01],\n",
       "        [1.67722553e-02, 9.68666911e-01, 4.19588992e-03, 5.07720886e-03,\n",
       "         5.28773293e-03],\n",
       "        [3.02402359e-02, 9.33631301e-01, 1.66641381e-02, 9.42663942e-03,\n",
       "         1.00376066e-02],\n",
       "        [2.57934816e-02, 9.13039923e-01, 2.81012151e-02, 8.55350308e-03,\n",
       "         2.45118756e-02],\n",
       "        [6.95879757e-02, 6.38515174e-01, 1.23972878e-01, 5.69743440e-02,\n",
       "         1.10949606e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how our model performs on the training data\n",
    "y_pred = model(x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJng31_Pi2R6",
    "outputId": "92a56e62-3e8b-4a45-b6d0-b7581bb6ce6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[1.60775296e-02, 9.59791422e-01, 1.24694565e-02, 4.27387562e-03,\n",
       "         7.38764415e-03],\n",
       "        [5.99917397e-03, 9.87714767e-01, 4.03423421e-03, 6.78302778e-04,\n",
       "         1.57347543e-03],\n",
       "        [4.86144796e-02, 8.47507834e-01, 5.12109138e-02, 1.03687225e-02,\n",
       "         4.22981009e-02],\n",
       "        [1.84902817e-01, 4.91020918e-01, 9.47416723e-02, 8.48343968e-02,\n",
       "         1.44500211e-01],\n",
       "        [1.28983073e-02, 9.60945904e-01, 1.14672389e-02, 5.58851613e-03,\n",
       "         9.10003111e-03]],\n",
       "\n",
       "       [[1.52008524e-02, 9.65144753e-01, 1.07962517e-02, 2.49629864e-03,\n",
       "         6.36180490e-03],\n",
       "        [1.12328585e-02, 9.53729510e-01, 1.86248086e-02, 8.69716611e-03,\n",
       "         7.71567831e-03],\n",
       "        [1.09880820e-01, 7.75187790e-01, 3.24392989e-02, 2.11186018e-02,\n",
       "         6.13734350e-02],\n",
       "        [3.37357223e-02, 8.14603388e-01, 7.68600702e-02, 2.95931660e-02,\n",
       "         4.52076495e-02],\n",
       "        [1.57899912e-02, 9.38233197e-01, 1.79915857e-02, 5.94395120e-03,\n",
       "         2.20412761e-02]],\n",
       "\n",
       "       [[8.19386318e-02, 8.41997743e-01, 2.76125334e-02, 1.33059919e-02,\n",
       "         3.51451077e-02],\n",
       "        [2.14639045e-02, 9.08513069e-01, 2.93683428e-02, 8.76096822e-03,\n",
       "         3.18937525e-02],\n",
       "        [7.16515258e-03, 9.84207451e-01, 4.37156111e-03, 1.73072226e-03,\n",
       "         2.52513355e-03],\n",
       "        [1.87031049e-02, 9.62900460e-01, 5.27832471e-03, 6.18595025e-03,\n",
       "         6.93209982e-03],\n",
       "        [3.11175007e-02, 9.13415313e-01, 2.87256520e-02, 2.90300325e-03,\n",
       "         2.38384977e-02]],\n",
       "\n",
       "       [[6.55811131e-02, 8.10819983e-01, 5.94442412e-02, 2.87703034e-02,\n",
       "         3.53843793e-02],\n",
       "        [5.60720079e-02, 9.02660966e-01, 1.65023785e-02, 8.52254964e-03,\n",
       "         1.62421186e-02],\n",
       "        [1.95213538e-02, 9.58502412e-01, 1.22605255e-02, 2.97909020e-03,\n",
       "         6.73664268e-03],\n",
       "        [1.06222183e-02, 9.61758554e-01, 1.08494274e-02, 9.94082913e-03,\n",
       "         6.82904618e-03],\n",
       "        [1.30411282e-01, 7.04484940e-01, 6.84216917e-02, 3.61161791e-02,\n",
       "         6.05659038e-02]],\n",
       "\n",
       "       [[2.12083422e-02, 9.46676016e-01, 1.91588271e-02, 1.52694702e-03,\n",
       "         1.14298565e-02],\n",
       "        [3.15497667e-02, 9.52408433e-01, 7.37974979e-03, 2.81979865e-03,\n",
       "         5.84226847e-03],\n",
       "        [3.62813510e-02, 9.05621886e-01, 2.75375377e-02, 1.08238962e-02,\n",
       "         1.97352692e-02],\n",
       "        [3.68614048e-02, 8.49207103e-01, 6.53592944e-02, 6.85668923e-03,\n",
       "         4.17154618e-02],\n",
       "        [5.73505722e-02, 8.46213102e-01, 4.81010117e-02, 1.69493034e-02,\n",
       "         3.13860103e-02]],\n",
       "\n",
       "       [[1.72498152e-02, 9.67998922e-01, 9.16234776e-03, 2.33817031e-03,\n",
       "         3.25077935e-03],\n",
       "        [2.28076223e-02, 9.38064694e-01, 1.84460729e-02, 2.41025467e-03,\n",
       "         1.82712413e-02],\n",
       "        [1.96162574e-02, 9.28117394e-01, 2.21447572e-02, 8.61050002e-03,\n",
       "         2.15111133e-02],\n",
       "        [1.01756137e-02, 9.64826405e-01, 1.01990364e-02, 5.54303965e-03,\n",
       "         9.25589539e-03],\n",
       "        [7.54266232e-03, 9.86467540e-01, 1.37331453e-03, 2.26021907e-03,\n",
       "         2.35625962e-03]],\n",
       "\n",
       "       [[1.07557610e-01, 6.16005778e-01, 9.94059145e-02, 8.46058130e-02,\n",
       "         9.24249068e-02],\n",
       "        [1.59192666e-01, 5.55931568e-01, 1.19241565e-01, 6.73188642e-02,\n",
       "         9.83153731e-02],\n",
       "        [6.38839230e-02, 7.97861636e-01, 6.96671531e-02, 2.96121556e-02,\n",
       "         3.89751568e-02],\n",
       "        [2.13696100e-02, 9.11317050e-01, 2.93317921e-02, 5.37548913e-03,\n",
       "         3.26060578e-02],\n",
       "        [1.75755657e-02, 9.63469028e-01, 9.56195593e-03, 1.85472611e-03,\n",
       "         7.53880106e-03]],\n",
       "\n",
       "       [[2.88275462e-02, 8.95130098e-01, 3.81233431e-02, 1.46674607e-02,\n",
       "         2.32515335e-02],\n",
       "        [1.14403225e-01, 5.55524468e-01, 1.24110930e-01, 6.67741224e-02,\n",
       "         1.39187276e-01],\n",
       "        [2.04155687e-02, 9.22194719e-01, 2.26590000e-02, 6.87526911e-03,\n",
       "         2.78554000e-02],\n",
       "        [2.24952400e-02, 9.50763702e-01, 1.27281155e-02, 4.73968778e-03,\n",
       "         9.27331112e-03],\n",
       "        [9.29474551e-03, 9.49107111e-01, 2.06842031e-02, 2.64854892e-03,\n",
       "         1.82654466e-02]],\n",
       "\n",
       "       [[1.14477351e-01, 6.23992026e-01, 6.94453418e-02, 7.48372301e-02,\n",
       "         1.17248066e-01],\n",
       "        [9.93120577e-03, 9.71869409e-01, 9.14605986e-03, 2.79438286e-03,\n",
       "         6.25904882e-03],\n",
       "        [1.00739755e-01, 6.21061623e-01, 1.25775397e-01, 5.65228574e-02,\n",
       "         9.59003344e-02],\n",
       "        [6.53877780e-02, 7.51762569e-01, 7.15561733e-02, 4.22566310e-02,\n",
       "         6.90368861e-02],\n",
       "        [8.16592351e-02, 7.50344515e-01, 6.88421875e-02, 3.96952853e-02,\n",
       "         5.94587773e-02]],\n",
       "\n",
       "       [[1.06520094e-01, 6.67963743e-01, 9.33751687e-02, 3.54741365e-02,\n",
       "         9.66668501e-02],\n",
       "        [3.56547255e-03, 9.93444204e-01, 1.43823295e-03, 7.00833858e-04,\n",
       "         8.51200544e-04],\n",
       "        [7.42459521e-02, 8.20186496e-01, 4.50296961e-02, 1.69227030e-02,\n",
       "         4.36151661e-02],\n",
       "        [6.79173693e-02, 7.59138227e-01, 6.94993734e-02, 4.32465039e-02,\n",
       "         6.01985492e-02],\n",
       "        [2.55561639e-02, 9.34769988e-01, 1.83136389e-02, 3.49019794e-03,\n",
       "         1.78700257e-02]]], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create test data and check how our model performs on it\n",
    "x2 = y + jax.random.normal(key=jax.random.key(seed=101), shape=y.shape)\n",
    "y_pred = model(x2)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WNk6oIZw2xo"
   },
   "source": [
    "Great! Looks like our model almost perfectly learned to filter out the noise from the `x` that we passed in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8rUNk_1xG1v"
   },
   "source": [
    "## Demo: Word Window Classification\n",
    "\n",
    "Until this part of the notebook, we have learned the fundamentals of JAX and built a basic network solving a toy task. Now we will attempt to solve an example NLP task. Here are the things we will learn:\n",
    "\n",
    "1. Data: Creating a Dataset of Batched Tensors\n",
    "2. Modeling\n",
    "3. Training\n",
    "4. Prediction\n",
    "\n",
    "In this section, our goal will be to train a model that will find the words in a sentence corresponding to a `LOCATION`, which will be always of span `1` (meaning that `San Fransisco` won't be recognized as a `LOCATION`). Our task is called `Word Window Classification` for a reason. Instead of letting our model to only take a look at one word in each forward pass, we would like it to be able to consider the context of the word in question. That is, for each word, we want our model to be aware of the surrounding words. Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_amzuUx8BJXI"
   },
   "source": [
    "### Data\n",
    "\n",
    "The very first task of any machine learning project is to set up our training set. Usually, there will be a training corpus we will be utilizing. In NLP tasks, the corpus would generally be a `.txt` or `.csv` file where each row corresponds to a sentence or a tabular datapoint. In our toy task, we will assume that we have already read our data and the corresponding labels into a `Python` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "mDiI1PLMw10z"
   },
   "outputs": [],
   "source": [
    "# Our raw data, which consists of sentences\n",
    "corpus = [\n",
    "    \"We always come to Paris\",\n",
    "    \"The professor is from Australia\",\n",
    "    \"I live in Stanford\",\n",
    "    \"He comes from Taiwan\",\n",
    "    \"The capital of Turkey is Ankara\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t33Uke9AE22s"
   },
   "source": [
    "#### Preprocessing\n",
    "\n",
    "To make it easier for our models to learn, we usually apply a few preprocessing steps to our data. This is especially important when dealing with text data. Here are some examples of text preprocessing:\n",
    "* **Tokenization**: Tokenizing the sentences into words.\n",
    "* **Lowercasing**: Changing all the letters to be lowercase.\n",
    "* **Noise removal:** Removing special characters (such as punctuations).\n",
    "* **Stop words removal**: Removing commonly used words.\n",
    "\n",
    "Which preprocessing steps are necessary is determined by the task at hand. For example, although it is useful to remove special characters in some tasks, for others they may be important (for example, if we are dealing with multiple languages). For our task, we will lowercase our words and tokenize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "fTGn8ANTzZXT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['we', 'always', 'come', 'to', 'paris'],\n",
       " ['the', 'professor', 'is', 'from', 'australia'],\n",
       " ['i', 'live', 'in', 'stanford'],\n",
       " ['he', 'comes', 'from', 'taiwan'],\n",
       " ['the', 'capital', 'of', 'turkey', 'is', 'ankara']]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The preprocessing function we will use to generate our training examples\n",
    "# Our function is a simple one, we lowercase the letters\n",
    "# and then tokenize the words.\n",
    "def preprocess_sentence(sentence):\n",
    "  return sentence.lower().split()\n",
    "\n",
    "# Create our training set\n",
    "train_sentences = [preprocess_sentence(sent) for sent in corpus]\n",
    "train_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4jzo5tp0Hza"
   },
   "source": [
    "For each training example we have, we should also have a corresponding label. Recall that the goal of our model was to determine which words correspond to a `LOCATION`. That is, we want our model to output `0` for all the words that are not `LOCATION`s and `1` for the ones that are `LOCATION`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "3wo1kcMAHFw7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1]]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set of locations that appear in our corpus\n",
    "locations = set([\"australia\", \"ankara\", \"paris\", \"stanford\", \"taiwan\", \"turkey\"])\n",
    "\n",
    "# Our train labels\n",
    "train_labels = [[1 if word in locations else 0 for word in sent] for sent in train_sentences]\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgVKH9M3RtPx"
   },
   "source": [
    "#### Converting Words to Embeddings\n",
    "\n",
    "Let's look at our training data a little more closely. Each datapoint we have is a sequence of words. On the other hand, we know that machine learning models work with numbers in vectors. How are we going to turn words into numbers? You may be thinking embeddings and you are right!\n",
    "\n",
    "Imagine that we have an embedding lookup table `E`, where each row corresponds to an embedding. That is, each word in our vocabulary would have a corresponding embedding row `i` in this table. Whenever we want to find an embedding for a word, we will follow these steps:\n",
    "1. Find the corresponding index `i` of the word in the embedding table: `word->index`.\n",
    "2. Index into the embedding table and get the embedding: `index->embedding`.\n",
    "\n",
    "Let's look at the first step. We should assign all the words in our vocabulary to a corresponding index. We can do it as follows:\n",
    "1. Find all the unique words in our corpus.\n",
    "2. Assign an index to each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "SjTDlfPyVp5z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'always',\n",
       " 'ankara',\n",
       " 'australia',\n",
       " 'capital',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'from',\n",
       " 'he',\n",
       " 'i',\n",
       " 'in',\n",
       " 'is',\n",
       " 'live',\n",
       " 'of',\n",
       " 'paris',\n",
       " 'professor',\n",
       " 'stanford',\n",
       " 'taiwan',\n",
       " 'the',\n",
       " 'to',\n",
       " 'turkey',\n",
       " 'we'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all the unique words in our corpus\n",
    "vocabulary = set(w for s in train_sentences for w in s)\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOxnKznOWXSC"
   },
   "source": [
    "`vocabulary` now contains all the words in our corpus. On the other hand, during the test time, we can see words that are not contained in our vocabulary. If we can figure out a way to represent the unknown words, our model can still reason about whether they are a `LOCATION` or not, since we are also looking at the neighboring words for each prediction.\n",
    "\n",
    "We introduce a special token, `<unk>`, to tackle the words that are out of vocabulary. We could pick another string for our unknown token if we wanted. The only requirement here is that our token should be unique: we should only be using this token for unknown words. We will also add this special token to our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "ygxYuE1DYeR3"
   },
   "outputs": [],
   "source": [
    "# Add the unknown token to our vocabulary\n",
    "vocabulary.add(\"<unk>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bsf4haL94AFu"
   },
   "source": [
    "Earlier we mentioned that our task was called `Word Window Classification` because our model is looking at the surroundings words in addition to the given word when it needs to make a prediction.\n",
    "\n",
    "For example, let's take the sentence \"We always come to Paris\". The corresponding training label for this sentence is `0, 0, 0, 0, 1` since only Paris, the last word, is a `LOCATION`. In one pass (meaning a call to `forward()`), our model will try to generate the correct label for one word. Let's say our model is trying to generate the correct label `1` for `Paris`. If we only allow our model to see `Paris`, but nothing else, we will miss out on the important information that the word `to` often times appears with `LOCATION`s.\n",
    "\n",
    "Word windows allow our model to consider the surrounding `+N` or `-N` words of each word when making a prediction. In our earlier example for `Paris`, if we have a window size of 1, that means our model will look at the words that come immediately before and after `Paris`, which are `to`, and, well, nothing. Now, this raises another issue. `Paris` is at the end of our sentence, so there isn't another word following it. Remember that we define the input dimensions of our models when we are initializing them. If we set the window size to be `1`, it means that our model will be accepting `3` words in every pass. We cannot have our model expect `2` words from time to time.\n",
    "\n",
    "The solution is to introduce a special token, such as `<pad>`, that will be added to our sentences to make sure that every word has a valid window around them. Similar to `<unk>` token, we could pick another string for our pad token if we wanted, as long as we make sure it is used for a unique purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "ZVQsjYi6ZegI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>', '<pad>', 'we', 'always', 'come', 'to', 'paris', '<pad>', '<pad>']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the <pad> token to our vocabulary\n",
    "vocabulary.add(\"<pad>\")\n",
    "\n",
    "# Function that pads the given sentence\n",
    "# We are introducing this function here as an example\n",
    "# We will be utilizing it later in the tutorial\n",
    "def pad_window(sentence, window_size, pad_token=\"<pad>\"):\n",
    "  window = [pad_token] * window_size\n",
    "  return window + sentence + window\n",
    "\n",
    "# Show padding example\n",
    "window_size = 2\n",
    "pad_window(train_sentences[0], window_size=window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqvgWKwSNpAd"
   },
   "source": [
    "Now that our vocabularly is ready, let's assign an index to each of our words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "BNCTQnKDa4oh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<unk>': 1,\n",
       " 'always': 2,\n",
       " 'ankara': 3,\n",
       " 'australia': 4,\n",
       " 'capital': 5,\n",
       " 'come': 6,\n",
       " 'comes': 7,\n",
       " 'from': 8,\n",
       " 'he': 9,\n",
       " 'i': 10,\n",
       " 'in': 11,\n",
       " 'is': 12,\n",
       " 'live': 13,\n",
       " 'of': 14,\n",
       " 'paris': 15,\n",
       " 'professor': 16,\n",
       " 'stanford': 17,\n",
       " 'taiwan': 18,\n",
       " 'the': 19,\n",
       " 'to': 20,\n",
       " 'turkey': 21,\n",
       " 'we': 22}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are just converting our vocabularly to a list to be able to index into it\n",
    "# Sorting is not necessary, we sort to show an ordered word_to_ind dictionary\n",
    "# That being said, we will see that having the index for the padding token\n",
    "# be 0 is convenient as some PyTorch functions use it as a default value\n",
    "# such as nn.utils.rnn.pad_sequence, which we will cover in a bit\n",
    "ix_to_word = sorted(list(vocabulary))\n",
    "\n",
    "# Creating a dictionary to find the index of a given word\n",
    "word_to_ix = {word: ind for ind, word in enumerate(ix_to_word)}\n",
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "pt-0SK67hMVo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_word[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELZuteqbdWd1"
   },
   "source": [
    "Great! We are ready to convert our training sentences into a sequence of indices corresponding to each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "ZNOxip15bMfH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence is: ['we', 'always', 'come', 'to', 'kuwait']\n",
      "Going from words to indices: [22, 2, 6, 20, 1]\n",
      "Going from indices to words: ['we', 'always', 'come', 'to', '<unk>']\n"
     ]
    }
   ],
   "source": [
    "# Given a sentence of tokens, return the corresponding indices\n",
    "def convert_token_to_indices(sentence, word_to_ix):\n",
    "  indices = []\n",
    "  for token in sentence:\n",
    "    # Check if the token is in our vocabularly. If it is, get it's index.\n",
    "    # If not, get the index for the unknown token.\n",
    "    if token in word_to_ix:\n",
    "      index = word_to_ix[token]\n",
    "    else:\n",
    "      index = word_to_ix[\"<unk>\"]\n",
    "    indices.append(index)\n",
    "  return indices\n",
    "\n",
    "# More compact version of the same function\n",
    "def _convert_token_to_indices(sentence, word_to_ix):\n",
    "  return [word_to_ind.get(token, word_to_ix[\"<unk>\"]) for token in sentence]\n",
    "\n",
    "# Show an example\n",
    "example_sentence = [\"we\", \"always\", \"come\", \"to\", \"kuwait\"]\n",
    "example_indices = convert_token_to_indices(example_sentence, word_to_ix)\n",
    "restored_example = [ix_to_word[ind] for ind in example_indices]\n",
    "\n",
    "print(f\"Original sentence is: {example_sentence}\")\n",
    "print(f\"Going from words to indices: {example_indices}\")\n",
    "print(f\"Going from indices to words: {restored_example}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jsXw8cB1xpH"
   },
   "source": [
    "In the example above, `kuwait` shows up as `<unk>`, because it is not included in our vocabulary. Let's convert our `train_sentences` to `example_padded_indices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "JRaKQwSJH-1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[22, 2, 6, 20, 15],\n",
       " [19, 16, 12, 8, 4],\n",
       " [10, 13, 11, 17],\n",
       " [9, 7, 8, 18],\n",
       " [19, 5, 14, 21, 12, 3]]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting our sentences to indices\n",
    "example_padded_indices = [convert_token_to_indices(s, word_to_ix) for s in train_sentences]\n",
    "example_padded_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZULjHBjHsEK"
   },
   "source": [
    "Now that we have an index for each word in our vocabularly, we can create an embedding table with `nnx.Embed` class in `JAX (Flax)`. It is called as follows `nnx.Embed(num_words, embedding_dimension)` where `num_words` is the number of words in our vocabulary and the `embedding_dimension` is the dimension of the embeddings we want to have. There is nothing fancy about `nnx.Embed`: it is just a wrapper class around a trainabe `NxE` dimensional tensor, where `N` is the number of words in our vocabulary and `E` is the number of embedding dimensions. This table is initially random, but it will change over time. As we train our network, the gradients will be backpropagated all the way to the embedding layer, and hence our word embeddings would be updated. We will initiliaze the embedding layer we will use for our model in our model, but we are showing an example here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State({\n",
       "  'embedding': VariableState(\n",
       "    type=Param,\n",
       "    value=Array([[ 3.51217270e-01,  5.26763022e-01, -4.20501053e-01,\n",
       "            -7.62650669e-01, -7.22563803e-01],\n",
       "           [-4.73633148e-02,  6.94514513e-01,  1.99710235e-01,\n",
       "            -8.48488331e-01,  4.44375962e-01],\n",
       "           [-7.83036351e-01, -3.28497887e-01,  3.33785653e-01,\n",
       "             6.07807398e-01,  1.22393698e-01],\n",
       "           [-3.56444776e-01,  2.08796978e-01,  6.49359897e-02,\n",
       "             7.55196088e-04, -8.47356141e-01],\n",
       "           [-1.13405414e-01,  1.18730918e-01, -5.13231337e-01,\n",
       "             6.54561281e-01,  4.54957813e-01],\n",
       "           [-9.56119150e-02, -3.83494079e-01,  1.86414085e-02,\n",
       "             2.14622915e-01, -2.31866419e-01],\n",
       "           [ 4.09342647e-01,  7.63373852e-01,  8.30148607e-02,\n",
       "            -5.72090387e-01, -5.33070326e-01],\n",
       "           [ 6.10590100e-01,  1.57741010e-01,  3.44011247e-01,\n",
       "            -3.61440815e-02, -4.50284958e-01],\n",
       "           [-3.84995013e-01, -3.05854857e-01, -5.37834108e-01,\n",
       "             6.71266794e-01, -1.15443192e-01],\n",
       "           [-1.96892455e-01, -3.50510716e-01, -2.28311107e-01,\n",
       "             8.38737190e-02, -2.06469774e-01],\n",
       "           [-3.78498614e-01,  1.81840405e-01, -1.97925404e-01,\n",
       "             4.42591429e-01,  2.64048129e-01],\n",
       "           [-4.54648226e-01,  3.88781279e-01, -4.57513422e-01,\n",
       "            -6.43754125e-01,  6.93895221e-01],\n",
       "           [ 3.41670215e-01, -2.28980571e-01, -1.32389092e+00,\n",
       "            -4.10905004e-01, -1.16661385e-01],\n",
       "           [ 2.46657014e-01,  3.40433866e-02, -1.41671553e-01,\n",
       "            -2.77797561e-02, -8.45516324e-01],\n",
       "           [-6.20684087e-01, -6.54152483e-02,  4.78360392e-02,\n",
       "            -2.23846193e-02,  4.37817536e-02],\n",
       "           [ 5.70847234e-03,  1.37353271e-01, -4.15841103e-01,\n",
       "             4.30666119e-01, -4.68404680e-01],\n",
       "           [ 1.35163680e-01, -1.22689575e-01,  6.53856516e-01,\n",
       "             1.26000896e-01,  2.06786245e-01],\n",
       "           [ 2.25967750e-01,  4.56736870e-02,  1.44704014e-01,\n",
       "             5.05350009e-02, -3.08686107e-01],\n",
       "           [-5.77608287e-01, -5.58721542e-01,  5.67021549e-01,\n",
       "             5.65270782e-01, -5.11007130e-01],\n",
       "           [-8.53732288e-01,  3.32256198e-01, -4.85098809e-01,\n",
       "             3.19113851e-01,  6.21136248e-01],\n",
       "           [-1.46546900e-01,  8.54678571e-01, -2.28169531e-01,\n",
       "            -5.16095459e-01, -3.22001390e-02],\n",
       "           [-4.97136498e-03,  3.26753825e-01,  5.68805277e-01,\n",
       "             4.39136893e-01,  4.36421841e-01],\n",
       "           [-8.11879635e-02,  1.12212040e-02,  5.11165619e-01,\n",
       "             1.88839391e-01,  3.32354814e-01]], dtype=float32)\n",
       "  )\n",
       "})"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an embedding table for our words\n",
    "embedding_dim = 5\n",
    "embeds = nnx.Embed(len(vocabulary), embedding_dim, rngs=nnx.Rngs(0))\n",
    "nnx.state(embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wI7ZTt4OkpPp"
   },
   "source": [
    "To get the word embedding for a word in our vocabulary, all we need to do is to create a lookup tensor. The lookup tensor is just a tensor containing the index we want to look up `nn.Embedding` class expects an index tensor that is of type Long Tensor, so we should create our tensor accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "nkldmcepjfh_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.00570847,  0.13735327, -0.4158411 ,  0.43066612, -0.46840468],      dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the embedding for the word Paris\n",
    "index = word_to_ix[\"paris\"]\n",
    "index_tensor = jnp.array(index, dtype=jnp.int32)\n",
    "paris_embed = embeds(index_tensor)\n",
    "paris_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "mUsdwBOxm6B4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 5.7084723e-03,  1.3735327e-01, -4.1584110e-01,  4.3066612e-01,\n",
       "        -4.6840468e-01],\n",
       "       [-3.5644478e-01,  2.0879698e-01,  6.4935990e-02,  7.5519609e-04,\n",
       "        -8.4735614e-01]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get multiple embeddings at once\n",
    "index_paris = word_to_ix[\"paris\"]\n",
    "index_ankara = word_to_ix[\"ankara\"]\n",
    "indices = [index_paris, index_ankara]\n",
    "indices_tensor = jnp.array(indices, dtype=jnp.int32)\n",
    "embeddings = embeds(indices_tensor)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bgSW3LPltkF"
   },
   "source": [
    "Usually, we define the embedding layer as part of our model, which you will see in the later sections of our notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHCXeQOamHU1"
   },
   "source": [
    "#### Batching Sentences\n",
    "\n",
    "We have learned about batches in class. Waiting our whole training corpus to be processed before making an update is costly. On the other hand, updating the parameters after every training example causes the loss to be less stable between updates. To combat these issues, we instead update our parameters after training on a batch of data. This allows us to get a better estimate of the gradient of the global loss. In this section, we will learn how to structure our data into batches using the `torch.util.data.DataLoader` class.\n",
    "\n",
    "We will be calling the `DataLoader` class as follows: `DataLoader(data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)`.  The `batch_size` parameter determines the number of examples per batch. In every epoch, we will be iterating over all the batches using the `DataLoader`. The order of batches is deterministic by default, but we can ask `DataLoader` to shuffle the batches by setting the `shuffle` parameter to `True`. This way we ensure that we don't encounter a bad batch multiple times.\n",
    "\n",
    "If provided, `DataLoader` passes the batches it prepares to the `collate_fn`. We can write a custom function to pass to the `collate_fn` parameter in order to print stats about our batch or perform extra processing. In our case, we will use the `collate_fn` to:\n",
    "1. Window pad our train sentences.\n",
    "2. Convert the words in the training examples to indices.\n",
    "3. Pad the training examples so that all the sentences and labels have the same length. Similarly, we also need to pad the labels. This creates an issue because when calculating the loss, we need to know the actual number of words in a given example. We will also keep track of this number in the function we pass to the `collate_fn` parameter.\n",
    "\n",
    "Because our version of the `collate_fn` function will need to access to our `word_to_ix` dictionary (so that it can turn words into indices), we will make use of the `partial` function in `Python`, which passes the parameters we give to the function we pass it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "OkvvVlo4jgFm"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "# TODO: see how we can remove dependency on torch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def custom_collate_fn(batch, window_size, word_to_ix):\n",
    "  # Break our batch into the training examples (x) and labels (y)\n",
    "  # We are turning our x and y into tensors because nn.utils.rnn.pad_sequence\n",
    "  # method expects tensors. This is also useful since our model will be\n",
    "  # expecting tensor inputs.\n",
    "  x, y = zip(*batch)\n",
    "\n",
    "  # Now we need to window pad our training examples. We have already defined a\n",
    "  # function to handle window padding. We are including it here again so that\n",
    "  # everything is in one place.\n",
    "  def pad_window(sentence, window_size, pad_token=\"<pad>\"):\n",
    "    window = [pad_token] * window_size\n",
    "    return window + sentence + window\n",
    "\n",
    "  # Pad the train examples.\n",
    "  x = [pad_window(s, window_size=window_size) for s in x]\n",
    "\n",
    "  # Now we need to turn words in our training examples to indices. We are\n",
    "  # copying the function defined earlier for the same reason as above.\n",
    "  def convert_tokens_to_indices(sentence, word_to_ix):\n",
    "    return [word_to_ix.get(token, word_to_ix[\"<unk>\"]) for token in sentence]\n",
    "\n",
    "  # Convert the train examples into indices.\n",
    "  x = [convert_tokens_to_indices(s, word_to_ix) for s in x]\n",
    "\n",
    "  # We will now pad the examples so that the lengths of all the example in\n",
    "  # one batch are the same, making it possible to do matrix operations.\n",
    "  # We set the batch_first parameter to True so that the returned matrix has\n",
    "  # the batch as the first dimension.\n",
    "  pad_token_ix = word_to_ix[\"<pad>\"]\n",
    "\n",
    "  # pad_sequence function expects the input to be a tensor, so we turn x into one\n",
    "  x = [torch.LongTensor(x_i) for x_i in x]\n",
    "  # TODO: see how we can efficiently pad_sequence with JAX\n",
    "  x_padded = nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=pad_token_ix)\n",
    "\n",
    "  # We will also pad the labels. Before doing so, we will record the number\n",
    "  # of labels so that we know how many words existed in each example.\n",
    "  lengths = [len(label) for label in y]\n",
    "  lenghts = jnp.array(lengths, dtype=jnp.int32)\n",
    "\n",
    "  y = [torch.LongTensor(y_i) for y_i in y]\n",
    "  y_padded = nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=0)\n",
    "\n",
    "  # We are now ready to return our variables. The order we return our variables\n",
    "  # here will match the order we read them in our training loop.\n",
    "  return jnp.array(x_padded), jnp.array(y_padded), lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "RfB0JKL2vZ6p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Batched Input:\n",
      "tf.Tensor(\n",
      "[[ 0  0 22  2  6 20 15  0  0  0]\n",
      " [ 0  0 19 16 12  8  4  0  0  0]], shape=(2, 10), dtype=int32)\n",
      "Batched Labels:\n",
      "tf.Tensor(\n",
      "[[0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]], shape=(2, 6), dtype=int32)\n",
      "Batched Lengths:\n",
      "tf.Tensor([5 5], shape=(2,), dtype=int32)\n",
      "\n",
      "Iteration 1\n",
      "Batched Input:\n",
      "tf.Tensor(\n",
      "[[ 0  0 10 13 11 17  0  0  0  0]\n",
      " [ 0  0  9  7  8 18  0  0  0  0]], shape=(2, 10), dtype=int32)\n",
      "Batched Labels:\n",
      "tf.Tensor(\n",
      "[[0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0]], shape=(2, 6), dtype=int32)\n",
      "Batched Lengths:\n",
      "tf.Tensor([4 4], shape=(2,), dtype=int32)\n",
      "\n",
      "Iteration 2\n",
      "Batched Input:\n",
      "tf.Tensor([[ 0  0 19  5 14 21 12  3  0  0]], shape=(1, 10), dtype=int32)\n",
      "Batched Labels:\n",
      "tf.Tensor([[0 0 0 1 0 1]], shape=(1, 6), dtype=int32)\n",
      "Batched Lengths:\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Parameters to be passed to the DataLoader\n",
    "data = list(zip(train_sentences, train_labels))\n",
    "batch_size = 2\n",
    "shuffle = True\n",
    "window_size = 2\n",
    "collate_fn = partial(custom_collate_fn, window_size=window_size, word_to_ix=word_to_ix)\n",
    "\n",
    "# Instantiate the DataLoader\n",
    "# loader = DataLoader(data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(collate_fn(data)).batch(batch_size=batch_size)\n",
    "\n",
    "# Go through one loop\n",
    "counter = 0\n",
    "for batched_x, batched_y, batched_lengths in dataset:\n",
    "  print(f\"Iteration {counter}\")\n",
    "  print(\"Batched Input:\")\n",
    "  print(batched_x)\n",
    "  print(\"Batched Labels:\")\n",
    "  print(batched_y)\n",
    "  print(\"Batched Lengths:\")\n",
    "  print(batched_lengths)\n",
    "  print(\"\")\n",
    "  counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93QOZSsMTFNF"
   },
   "source": [
    "The batched input tensors you see above will be passed into our model. On the other hand, we started off saying that our model will be a window classifier. The way our input tensors are currently formatted, we have all the words in a sentence in one datapoint. When we pass this input to our model, it needs to create the windows for each word, make a prediction as to whether the center word is a `LOCATION` or not for each window, put the predictions together and return.\n",
    "\n",
    "We could avoid this problem if we formatted our data by breaking it into windows beforehand. In this example, we will instead how our model take care of the formatting.\n",
    "\n",
    "Given that our `window_size` is `N` we want our model to make a prediction on every `2N+1` tokens. That is, if we have an input with `9` tokens, and a `window_size` of `2`, we want our model to return `5` predictions. This makes sense because before we padded it with `2` tokens on each side, our input also had `5` tokens in it!\n",
    "\n",
    "We can create these windows by using for loops, but there is a faster `PyTorch` alternative, which is the `unfold(dimension, size, step)` method. We can create the windows we need using this method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMZu-pxLVxHQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: \n",
      "tf.Tensor([[ 0  0 19  5 14 21 12  3  0  0]], shape=(1, 10), dtype=int32)\n",
      "\n",
      "Windows: \n",
      "[[[ 0  0 19  5 14]\n",
      "  [ 0 19  5 14 21]\n",
      "  [19  5 14 21 12]\n",
      "  [ 5 14 21 12  3]\n",
      "  [14 21 12  3  0]\n",
      "  [21 12  3  0  0]]]\n"
     ]
    }
   ],
   "source": [
    "def sliding_window_batched(inputs: jnp.array, window_size: int):\n",
    "    batch_size, seq_length = inputs.shape\n",
    "    num_windows = seq_length - window_size + 1\n",
    "    \n",
    "    # This function gets a single window for all sequences in the batch\n",
    "    def get_window(start_idx: int):\n",
    "        # dynamic_slice takes (operand, start_indices, slice_sizes)\n",
    "        # We need start indices for both batch and sequence dimensions\n",
    "        start_indices = jnp.array([0, start_idx])  # Start at beginning of batch\n",
    "        slice_sizes = jnp.array([batch_size, window_size])\n",
    "        return lax.dynamic_slice(inputs, start_indices, slice_sizes)\n",
    "    \n",
    "    # Create all windows by mapping over start indices\n",
    "    windows = jax.vmap(get_window)(jnp.arange(num_windows))\n",
    "    \n",
    "    # Rearrange from (num_windows, batch_size, window_size) \n",
    "    # to (batch_size, num_windows, window_size)\n",
    "    return jnp.transpose(windows, (1, 0, 2))\n",
    "\n",
    "# Print the original tensor\n",
    "print(f\"Original Tensor: \")\n",
    "print(batched_x)\n",
    "print(\"\")\n",
    "\n",
    "# Create the 2 * 2 + 1 chunks\n",
    "chunk = sliding_window_batched(jnp.array(batched_x), 2 * window_size + 1)\n",
    "print(f\"Windows: \")\n",
    "print(jnp.array(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlDbOpeoSKxd"
   },
   "source": [
    "### Model\n",
    "\n",
    "Now that we have prepared our data, we are ready to build our model. We have learned how to write custom `nnx.Module` classes. We will do the same here and put everything we have learned so far together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "JLTU4h76NLYm"
   },
   "outputs": [],
   "source": [
    "class WordWindowClassifier(nnx.Module):\n",
    "\n",
    "  def __init__(self, hyperparameters, vocab_size, pad_ix=0, rng_seed=0):\n",
    "    super(WordWindowClassifier, self).__init__()\n",
    "\n",
    "    \"\"\" Instance variables \"\"\"\n",
    "    self.window_size = hyperparameters[\"window_size\"]\n",
    "    self.embed_dim = hyperparameters[\"embed_dim\"]\n",
    "    self.hidden_dim = hyperparameters[\"hidden_dim\"]\n",
    "    self.freeze_embeddings = hyperparameters[\"freeze_embeddings\"]\n",
    "    self.rng_seed = rng_seed\n",
    "\n",
    "    \"\"\" Embedding Layer\n",
    "    Takes in a tensor containing embedding indices, and returns the\n",
    "    corresponding embeddings. The output is of dim\n",
    "    (number_of_indices * embedding_dim).\n",
    "\n",
    "    If freeze_embeddings is True, set the embedding layer parameters to be\n",
    "    non-trainable. This is useful if we only want the parameters other than the\n",
    "    embeddings parameters to change.\n",
    "\n",
    "    \"\"\"\n",
    "    # self.embeds = nn.Embedding(vocab_size, self.embed_dim, padding_idx=pad_ix)\n",
    "    self.embeds = nnx.Embed(vocab_size, self.embed_dim, rngs=nnx.Rngs(self.rng_seed))\n",
    "    # if self.freeze_embeddings:\n",
    "    #   self.embed_layer.weight.requires_grad = False\n",
    "\n",
    "    \"\"\" Hidden Layer\n",
    "    \"\"\"\n",
    "    full_window_size = 2 * window_size + 1\n",
    "    self.hidden_layer = nnx.Sequential(\n",
    "      nnx.Linear(full_window_size * self.embed_dim, self.hidden_dim, rngs=nnx.Rngs(self.rng_seed))\n",
    "    )\n",
    "\n",
    "    \"\"\" Output Layer\n",
    "    \"\"\"\n",
    "    self.output_layer = nnx.Linear(self.hidden_dim, 1, rngs=nnx.Rngs(self.rng_seed))\n",
    "\n",
    "  def __call__(self, inputs):\n",
    "    \"\"\"\n",
    "    Let B:= batch_size\n",
    "        L:= window-padded sentence length\n",
    "        D:= self.embed_dim\n",
    "        S:= self.window_size\n",
    "        H:= self.hidden_dim\n",
    "\n",
    "    inputs: a (B, L) tensor of token indices\n",
    "    \"\"\"\n",
    "    B, L = inputs.shape\n",
    "\n",
    "    \"\"\"\n",
    "    Reshaping.\n",
    "    Takes in a (B, L) LongTensor\n",
    "    Outputs a (B, L~, S) LongTensor\n",
    "    \"\"\"\n",
    "    # Fist, get our word windows for each word in our input.\n",
    "    token_windows = sliding_window_batched(inputs, 2 * self.window_size + 1)\n",
    "    _, n_windows, _ = token_windows.shape\n",
    "\n",
    "    # Good idea to do internal tensor-size sanity checks, at the least in comments!\n",
    "    assert token_windows.shape == (B, n_windows, 2 * self.window_size + 1)\n",
    "\n",
    "    \"\"\"\n",
    "    Embedding.\n",
    "    Takes in a tensor of size (B, L~, S)\n",
    "    Outputs a (B, L~, S, D) FloatTensor.\n",
    "    \"\"\"\n",
    "    embedded_windows = self.embeds(token_windows)\n",
    "\n",
    "    \"\"\"\n",
    "    Reshaping.\n",
    "    Takes in a (B, L~, S, D) FloatTensor.\n",
    "    Resizes it into a (B, L~, S*D) FloatTensor.\n",
    "    -1 argument \"infers\" what the last dimension should be based on leftover axes.\n",
    "    \"\"\"\n",
    "    embedded_windows = embedded_windows.reshape(B, n_windows, -1)\n",
    "\n",
    "    \"\"\"\n",
    "    Layer 1.\n",
    "    Takes in a (B, L~, S*D) FloatTensor.\n",
    "    Resizes it into a (B, L~, H) FloatTensor\n",
    "    \"\"\"\n",
    "    layer_1 = nnx.tanh(self.hidden_layer(embedded_windows))\n",
    "\n",
    "    \"\"\"\n",
    "    Layer 2\n",
    "    Takes in a (B, L~, H) FloatTensor.\n",
    "    Resizes it into a (B, L~, 1) FloatTensor.\n",
    "    \"\"\"\n",
    "    output = self.output_layer(layer_1)\n",
    "\n",
    "    \"\"\"\n",
    "    Softmax.\n",
    "    Takes in a (B, L~, 1) FloatTensor of unnormalized class scores.\n",
    "    Outputs a (B, L~, 1) FloatTensor of (log-)normalized class scores.\n",
    "    \"\"\"\n",
    "    output = nnx.sigmoid(output)\n",
    "    output = output.reshape(B, -1)\n",
    "\n",
    "    return output\n",
    "  \n",
    "@staticmethod\n",
    "def sliding_window_batched(inputs: jnp.array, window_size: int):\n",
    "    batch_size, seq_length = inputs.shape\n",
    "    num_windows = seq_length - window_size + 1\n",
    "    \n",
    "    # This function gets a single window for all sequences in the batch\n",
    "    def get_window(start_idx: int):\n",
    "        # dynamic_slice takes (operand, start_indices, slice_sizes)\n",
    "        # We need start indices for both batch and sequence dimensions\n",
    "        start_indices = jnp.array([0, start_idx])  # Start at beginning of batch\n",
    "        slice_sizes = jnp.array([batch_size, window_size])\n",
    "        return lax.dynamic_slice(inputs, start_indices, slice_sizes)\n",
    "    \n",
    "    # Create all windows by mapping over start indices\n",
    "    windows = jax.vmap(get_window)(jnp.arange(num_windows))\n",
    "    \n",
    "    # Rearrange from (num_windows, batch_size, window_size) \n",
    "    # to (batch_size, num_windows, window_size)\n",
    "    return jnp.transpose(windows, (1, 0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avy1fnyAvEcd"
   },
   "source": [
    "### Training\n",
    "\n",
    "We are now ready to put everything together. Let's start with preparing our data and intializing our model. We can then intialize our optimizer and define our loss function. This time, instead of using one of the predefined loss function as we did before, we will define our own loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "bInu1VqjHsfj"
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "data = list(zip(train_sentences, train_labels))\n",
    "batch_size = 2\n",
    "shuffle = True\n",
    "window_size = 2\n",
    "collate_fn = partial(custom_collate_fn, window_size=window_size, word_to_ix=word_to_ix)\n",
    "\n",
    "# Instantiate a DataLoader\n",
    "loader = tf.data.Dataset.from_tensor_slices(collate_fn(data)).batch(batch_size=batch_size)\n",
    "\n",
    "# Initialize a model\n",
    "# It is useful to put all the model hyperparameters in a dictionary\n",
    "model_hyperparameters = {\n",
    "    \"batch_size\": 4,\n",
    "    \"window_size\": 2,\n",
    "    \"embed_dim\": 25,\n",
    "    \"hidden_dim\": 25,\n",
    "    \"freeze_embeddings\": False,\n",
    "}\n",
    "\n",
    "vocab_size = len(word_to_ix)\n",
    "model = WordWindowClassifier(model_hyperparameters, vocab_size)\n",
    "\n",
    "# Define an optimizer\n",
    "learning_rate = 0.01\n",
    "sgd = optax.sgd(learning_rate=learning_rate)\n",
    "optimizer = nnx.Optimizer(model, sgd)\n",
    "\n",
    "# Define a loss function, which computes to binary cross entropy loss\n",
    "def loss_function(model, batch_inputs, batch_labels, batch_lengths):\n",
    "    # jax.value_and_grad computes the grad wrt the first argument\n",
    "    # so model object needs to be the first argument\n",
    "    batch_preds = model(batch_inputs)\n",
    "\n",
    "    # Calculate the loss for the whole batch\n",
    "    loss = optax.losses.sigmoid_binary_cross_entropy(batch_preds, batch_labels).sum()\n",
    "\n",
    "    # Rescale the loss. Remember that we have used lengths to store the\n",
    "    # number of words in each training example\n",
    "    loss = loss / batch_lengths.sum()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHxpxDkFHfQE"
   },
   "source": [
    "Unlike our earlier example, this time instead of passing all of our training data to the model at once in each epoch, we will be utilizing batches. Hence, in each training epoch iteration, we also iterate over the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_to_jax(arr):\n",
    "  return jax.dlpack.from_dlpack(tf.experimental.dlpack.to_dlpack(arr))\n",
    "\n",
    "def jax_to_tf(arr):\n",
    "  return tf.experimental.dlpack.from_dlpack(jax.dlpack.to_dlpack(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "QL9IDgIOvHca"
   },
   "outputs": [],
   "source": [
    "# Function that will be called in every epoch\n",
    "def train_epoch(loss_function, optimizer, model, loader):\n",
    "\n",
    "  # Keep track of the total loss for the batch\n",
    "  total_loss = 0\n",
    "  for batch_inputs, batch_labels, batch_lengths in loader:\n",
    "    # Convert to JAX w/o copying memory\n",
    "    batch_inputs, batch_labels, batch_lengths = tf_to_jax(batch_inputs), tf_to_jax(batch_labels), tf_to_jax(batch_lengths)\n",
    "    loss_, grads = nnx.value_and_grad(loss_function)(model, batch_inputs, batch_labels, batch_lengths)\n",
    "    optimizer.update(grads)\n",
    "    total_loss += loss_\n",
    "\n",
    "  return total_loss\n",
    "\n",
    "\n",
    "# Function containing our main training loop\n",
    "def train(loss_function, optimizer, model, loader, num_epochs=10000):\n",
    "\n",
    "  # Iterate through each epoch and call our train_epoch function\n",
    "  for epoch in range(num_epochs):\n",
    "    epoch_loss = train_epoch(loss_function, optimizer, model, loader)\n",
    "    if epoch % 100 == 0: print(epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjf75cnzJ4n6"
   },
   "source": [
    "Let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "Kav8kwVBJ6XW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2505436\n",
      "2.8879259\n",
      "2.716799\n",
      "2.645041\n",
      "2.6102877\n",
      "2.5898073\n",
      "2.5750124\n",
      "2.5617964\n",
      "2.5473454\n",
      "2.5287414\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "num_epochs = 1000\n",
    "train(loss_function, optimizer, model, loader, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-k7Pav4LdQJ"
   },
   "source": [
    "### Prediction\n",
    "\n",
    "Let's see how well our model is at making predictions. We can start by creating our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "-v5X69a2Lkbm"
   },
   "outputs": [],
   "source": [
    "# Create test sentences\n",
    "test_corpus = [\"She comes from Paris\", \"Stanford is not where he lives\"]\n",
    "test_sentences = [s.lower().split() for s in test_corpus]\n",
    "test_labels = [[0, 0, 0, 1], [1, 0, 0, 0, 0, 0]]\n",
    "\n",
    "# Create a test loader\n",
    "test_data = list(zip(test_sentences, test_labels))\n",
    "batch_size = 1\n",
    "shuffle = False\n",
    "window_size = 2\n",
    "collate_fn = partial(custom_collate_fn, window_size=2, word_to_ix=word_to_ix)\n",
    "\n",
    "test_loader = tf.data.Dataset.from_tensor_slices(collate_fn(test_data)).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlBa8xaNMZgv"
   },
   "source": [
    "Let's loop over our test examples to see how well we are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGYn8CAoMTjX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0]]\n",
      "[[0.01398687 0.02790629 0.04582718 0.31703278 0.02662954 0.02201691]]\n",
      "[[1 0 0 0 0 0]]\n",
      "[[0.01715227 0.01450206 0.05668084 0.12209436 0.04397918 0.06782205]]\n"
     ]
    }
   ],
   "source": [
    "for test_instance, labels, _ in test_loader:\n",
    "  batch_inputs, batch_labels = tf_to_jax(test_instance), tf_to_jax(labels)\n",
    "  outputs = model(batch_inputs)\n",
    "  print(batch_labels)\n",
    "  print(outputs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jax-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
